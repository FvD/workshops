---
title: "4 - Evaluar modelos - Ejercicios"
subtitle: "Introducciendo Tidymodels"
editor_options: 
  chunk_output_type: console
---

Recomendamos que reinicie R después de cada sección

## Preparación

Preparación despues de la 3ra sección

```{r}
library(tidymodels)

library(tidymodels)

set.seed(123)
taxi <- readRDS("archive/2024-03-conectaR-spanish/taxi.rds")

taxi_separar <- initial_split(taxi, prop = 0.8, strata = propina)
taxi_entrenar <- training(taxi_separar)
taxi_prueba <- testing(taxi_separar)

arbol_espec <- decision_tree(cost_complexity = 0.0001, mode = "classification")
arbol_flujo <- workflow(propina ~ ., arbol_espec)
taxi_ajustado <- fit(arbol_flujo, taxi_entrenar)
```

## Métricas de la calidad de modelo

Utiliza `conf_mat()` para ver que tan bien predice el modelo

```{r}
augment(taxi_ajustado, new_data = taxi_entrenar) %>%
  conf_mat(truth = propina, estimate = .pred_class)
```

También tiene buenas funciones para gráficar

```{r}
augment(taxi_ajustado, new_data = taxi_entrenar) %>%
  conf_mat(truth = propina, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

También puedes usarlo para calcular las métricas

```{r}
augment(taxi_fit, new_data = taxi_train) %>%
  accuracy(truth = tip, estimate = .pred_class)
```

Todas las funciones de yardstick también funcionan con datos agrupados

```{r}
augment(taxi_fit, new_data = taxi_train) %>%
  group_by(local) %>%
  accuracy(truth = tip, estimate = .pred_class)
```

Los sets the métricas son una manera de combinar varias métricas 

```{r}
taxi_metrics <- metric_set(accuracy, specificity, sensitivity)

augment(taxi_fit, new_data = taxi_train) %>%
  taxi_metrics(truth = tip, estimate = .pred_class)
```

## Tu turno

Calcula y gráfica una curva ROC para tu modelo

¿Que datos son utilizados en la curva ROC?

```{r}
# Your code here!

```

## Los peligros del sobreajustar

¡Es malo re-predecir en el set the entrenamiento!

```{r}
taxi_ajustado %>%
  augment(taxi_entrenar)
```

"Resubstitution estimate" - This should be the best possible performance that you could ever achieve, but it can be very misleading!

"Resubstitución en los datos de entrenamiento" - Esta va a ser la mejor calidad
que vamos a obtener, pero es bastante engañoso

```{r}
taxi_ajustado %>%
  augment(taxi_entrenar) %>%
  accuracy(propina, .pred_class)
```

Ahora, ¿ves que contra el set the prueba, la calidad baja? Esto es mas cercano
a como la calidad sería en la vida "real"

```{r}
taxi_ajustado %>%
  augment(taxi_prueba) %>%
  accuracy(propina, .pred_class)
```

## Tu turno

Usa `augment()` y una función de métrica para calcular una métrica de classificación,
por ejemplo `brier_class()`

Calcula las métricas para los datos de entrenamiento y de prueba para
demonstrar el sobreajuste

Nota la evidencia de sobreajuste

```{r}
# Your code here!

# Use `augment()` and `brier_class()` with `taxi_fit`
taxi_fit
```

## Tu turno

Si usamos 10 plieges (folds), cual es el porcentaje de datos de entrenamiento

-   cuantos terminan en análisis
-   cuantos terminan en evaluación (assesment)

...para **cada** pliege?

## Remuestreo

```{r}
vfold_cv(taxi_entrenar) 
```

¿Cual es el resultado del remuestreo?

```{r}
taxi_plieges <- vfold_cv(taxi_entrenar)
taxi_plieges$splits[1:3]
```

tratificar usualmente ayuda, y con pocos malas consecuencias 

```{r}
vfold_cv(taxi_entrenar, strata = propina)
```

Usaremos esto:

```{r}
set.seed(123)
taxi_plieges <- vfold_cv(taxi_entrenar, v = 10, strata = propina)
taxi_plieges
```

## Evaluating model performance

```{r}
# Fit the workflow on each analysis set,
# then compute performance on each assessment set
taxi_res <- fit_resamples(taxi_wflow, taxi_plieges)
taxi_res
```

Aggregate metrics

```{r}
taxi_res %>%
  collect_metrics()
```

If you want to analyze the assessment set (i.e. holdout) predictions, then you need to adjust the control object and tell it to save them:

```{r}
# Save the assessment set results
ctrl_taxi <- control_resamples(save_pred = TRUE)

taxi_res <- fit_resamples(taxi_wflow, taxi_plieges, control = ctrl_taxi)

taxi_preds <- collect_predictions(taxi_res)
taxi_preds
```

## Bootstrapping

```{r}
set.seed(3214)
bootstraps(taxi_train)
```

## Your turn

Create:

- Monte Carlo Cross-Validation sets
- validation set

(use the reference guide to find the functions)

https://rsample.tidymodels.org/reference/index.html

Don't forget to set a seed when you resample!

```{r}
# Your code here!

```

## Create a random forest model

```{r}
rf_spec <- rand_forest(trees = 1000, mode = "classification")
rf_spec
```

```{r}
rf_wflow <- workflow(tip ~ ., rf_spec)
rf_wflow
```

## Your turn

Use `fit_resamples()` and `rf_wflow` to:

- Keep predictions
- Compute metrics

```{r}
# Your code here!

```

## Evaluate a workflow set

```{r}
wf_set <- workflow_set(list(tip ~ .), list(tree_spec, rf_spec))
wf_set
```

```{r}
wf_set_fit <- wf_set %>%
  workflow_map("fit_resamples", resamples = taxi_plieges)

wf_set_fit
```

Rank the sets of models by their aggregate metric performance

```{r}
wf_set_fit %>%
  rank_results()
```

## Your turn

When do you think a workflow set would be useful?

Discuss with your neighbors!

## The final fit

```{r}
# `taxi_split` has train + test info
final_fit <- last_fit(rf_wflow, taxi_split) 

final_fit
```

Test set metrics:

```{r}
collect_metrics(final_fit)
```

Test set predictions:

```{r}
collect_predictions(final_fit)
```

```{r}
collect_predictions(final_fit) %>%
  ggplot(aes(.pred_class, fill = tip)) + 
  geom_bar() 
```

```{r}
extract_workflow(final_fit)
```

## Your turn

Which model do you think you would decide to use?

What surprised you the most?

If you're taking Advanced tidymodels tomorrow, what is one thing you are looking forward to learning?
